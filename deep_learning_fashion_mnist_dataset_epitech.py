# -*- coding: utf-8 -*-
"""deep-learning-fashion-mnist-dataset-epitech.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ie1sdvXXUqbQq8If10mQAeuJU7_sScyW
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from sys import version_info
print(version_info)

# Load the data set
fashion_mnist = tf.keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# turn the gray scale into float entrer 0 to 1
train_images = train_images / 255.0

test_images = test_images / 255.0

# Creation of model 

model = keras.models.Sequential()

model.add(keras.layers.Input((28,28,1)))

# We add one layer for convolution with 32 filters
model.add(keras.layers.Conv2D(32, (3,3),  activation='relu'))

# We add pooling layer
model.add(keras.layers.MaxPooling2D((2,2)))

# We add Dropout layer for reset the state for neral
model.add(keras.layers.Dropout(0.2))

model.add(keras.layers.Flatten())
# We add one layer of normal network layer
model.add(keras.layers.Dense(128, activation='relu'))
model.add(keras.layers.Dropout(0.5))

# And for finish we add a final layer of final clasification
model.add(keras.layers.Dense(10, activation='softmax'))

model.summary()

# compile the model with adam optimizer for reduse the lost teste

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# train the model with 20 epochs with the train dataset
model.fit(train_images, train_labels, epochs=20)

score = model.evaluate(test_images, test_labels, verbose=0)

print(f'Test loss     : {score[0]:4.4f}')
print(f'Test accuracy : {score[1]:4.4f}')

def plot_image(i, predictions_array, true_label, img):
  true_label, img = true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  true_label = true_label[i]
  plt.grid(False)
  plt.xticks(range(10))
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

probability_model = tf.keras.Sequential([model, 
                                         tf.keras.layers.Softmax()])

if __name__ == "__main__":
  predictions = probability_model.predict(test_images)

# Plot the first X test images, their predicted labels, and the true labels.
  # Color correct predictions in blue and incorrect predictions in red.
  num_rows = 10
  num_cols = 3
  num_images = num_rows*num_cols
  plt.figure(figsize=(2*2*num_cols, 2*num_rows))
  for i in range(num_images):
    plt.subplot(num_rows, 2*num_cols, 2*i+1)
    plot_image(i, predictions[i], test_labels, test_images)
    plt.subplot(num_rows, 2*num_cols, 2*i+2)
    plot_value_array(i, predictions[i], test_labels)
  plt.tight_layout()
  plt.show()